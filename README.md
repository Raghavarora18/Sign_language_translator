# Sign Language Translator

## Overview

This project is an end-to-end **real-time Sign Language Translation system** designed to recognize hand gestures and translate them into textual representations. The system focuses on **alphabet-level and space-aware sign recognition**, with an emphasis on real-time usability and clean, production-ready structure.

The project is built using **YOLO-based object detection** for hand gesture recognition and supports **keyboard-assisted control** to improve robustness during live inference.

---

## Key Features

*  **Real-time sign language detection** using webcam input
*  YOLO-based hand gesture recognition pipeline
*  Keyboard-assisted control for delete, backspace, and space handling
*  Modular and clean `src/`-based code structure
*  Debug and tuning utilities for real-time performance
*  Dataset and raw images excluded for clean version control

---
## Technology Stack

* Python
* YOLO (Object Detection)
* OpenCV for real-time video capture
* NumPy / PyTorch for model handling
* Git & GitHub for version control
---

## Author
Raghav Arora
B.Tech â€“ Artificial Intelligence & Machine Learning

**This project is intended for educational and research purposes and demonstrates applied computer vision and real-time ML system design.**
